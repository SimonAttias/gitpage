DECODING BIASES IN ARTIFICIAL INTELLIGENCE - FINAL PAPER 

INTRODUCTION

In 2019, the BBC ran a story about a 12-year-old girl who, having barely joined Instagram, was instantly bombarded with ads for beauty and health products. It turns out that she was actually much more interested in athletic and academic pursuits, and had joined the platform to follow the accounts of her sports idols. As a society, we are increasingly becoming aware of the dangers of sexist stereotypes. We are also aware of the immense harm that these kinds of imagery have on self-confidence and body image. 
As we read this story, we realized just how big the amount of information that Instagram has on us is, and how it influences the advertisements sent to our feed. We therefore decided to study the biases in Instagram’s ad selection process. We increasingly realized that targeted advertising can be very harmful, and that we might have interests that we did not explicitly nor publicly express, but that are figured out in ways algorithms are aware of.

HYPOTHESIS

Our hypothesis is that Instagram’s targeted ads rely heavily on the self-declared gender 
The goal of our study is to take a user-focused approach to understand and analyse what data is used to generate potentially gendered-biased Instagram ads, and use our results to inform and open the debate on these covert practices. 

Note of the authors: this study deliberately relies on the “classical” vision of gender, as a bi-categorical variable. Our rationale is twofold: first, Instagram only allows for two such gender categories when signing up for an account (in addition to the gender-neutral category, which we also used). Second, given the rather limited scale of our research project, it is both easier and more accurate to focus on the male/female divide.


LITERATURE REVIEW

As academia starts to catch up with big tech companies’ covert efforts to amass the biggest amount of data possible on its users, the literature on biases in ad algorithms is growing strong. One of the main (and most mediatized) issues regarding social media advertising is obviously the issue of political ads. Digital advertising on social media platforms is hugely popular due to how they empower the client’s ad to target messages directed at users with a never-seen-before accuracy, including inferences about the user’s political affiliations (Ali, 2019) (Heilweil, 2020). Prior work has shown that platforms’ ad algorithms can selectively choose to deliver ads within the intended target audiences in ways that more often than not lead to demographic skews. These skews always go along gender lines, often without the advertiser’s nor the public’s knowledge (Brown et al., 2018).
When it comes to the content of the ads themselves, examples like the aforementioned case of the 12-year old British girl are numerous and deserve our attention. Facebook Inc., Instagram’s parent company, disproportionately shows certain types of job advertisements to women and men, calling into question the company’s alleged efforts to root out biases in its algorithms (Jeff Horwitz, 2021). A 2018 Harvard study showed that, despite explicit intentions by the ad-producer to be gender neutral, a Facebook/Instagram advertisement for STEM (Science, Technology, Engineering, Math) careers had been shown much more often to men than women on the platform (Lambrecht, Anja, Catherine Tucker, 2018).  
Women continue to be sexualized, stereotyped, and under-represented in online ads when compared to men (Jen Gennai, 2020). There is clear evidence that these portrayals have consequential real-world effects on the way women behave and are treated. This is why we felt the need to perform this study, as it not only concerns Instagram users, but society as a whole. 
“One of our top priorities is protecting people from discrimination” said Sheryl Sandberg, Facebook’s Chief Operating Officer, in 2019. This statement came after Facebook had just launched a new, supposedly unbiased algorithm to display ads on its multiple platforms. As academia has proven (Ava Kofman, Ariana Tobin, 2019), and that we would like to verify in this study, these efforts seem not to be working as well as the executives at Facebook claim. 


METHODOLOGY

Our study uses the so-called “netnographic approach” (as theorized by Costello et al., 2017). Netnography is a data collection technique which is ‘a qualitative research methodology that adapts ethnographic research techniques through electronic networks’. Netnography consists of a thorough analysis of data in a natural setting and without the intervention of the researcher (Bailey, 2007). It is an unobtrusive way of gaining information, especially useful to gather data on topics such as gender issues (Gilchrist, Ravenscroft, et al., 2011). We will follow the  netnographic approach to conduct the analyses as part of our research. 

What Instagram tells its users
Whenever a user is sent an ad on their Instagram feed, a small icon on the add allows the user to get some information about the add, and why they see this particular ad. Here’s what Instagram tells us: 
How does Instagram decide which ads to show me? We want to show you ads from businesses that are relevant to you, and to do that we use information about what you do on Instagram as well as your activity on third-party sites and apps you use. We also may use information provided by businesses outside of Instagram or Facebook Company Products to decide which ads to show you. For example, you might see ads based on the people you follow and posts you like on Instagram, your information, the websites and apps you visit, or information advertisers, their partners, and our marketing partners share with us that they already have, like your email address.

The anonymization process to control for “data contamination”
As soon as we read this informative message, we quickly realized how difficult it would be to create a perfectly virgin instagram account, devoid of any prior data, in order to avoid what we’ve called a “contamination” of our experiment (meaning when information that is not explicitly collected by Instagram is used to steer our ads in a certain direction). 

After a painstaking process of trial and error, we came up with what we believe is the most secure and safe way of creating an account without any sort of   contamination (or with as little contamination as possible). 
First, we employed a single computer to create the email addresses that would later be used to open our experiment’s Instagram profile.
Second, we turned on a secure VPN connection, to make sure that our IP address would be untraceable. As such, neither the email provider, nor Instagram, could trace the email addresses back to our computer and our browsing histories. 
Third, we downloaded a new browser without any browsing history, namely Mozilla Firefox, and solely navigated using private navigation. 
Fourth, we created twenty (20) email addresses through ProtonMail, the safest and most secure email provider according to professionals. Each email address was created following a rationalized identical format: “saxo.phone[XX]@protonmail.com”, where the “X” is a given number. The use of “saxo.phone” is meant to throw off any attempt by Instagram to identify the user’s gender via their email (i.e. Instagram could very well identify a “john.deer@[...]” as a male. 

Following this thorough (some might say almost paranoid) process, we had thus created a perfectly hermetic and gender-neutral environment that we then used to create our twenty (20) experimental Instagram profile. The problem with Instagram is that, despite the EU’s GDPR, you cannot access the platform without explicitly consenting to cookie collections. This is why we painstakingly continued working from a single computer, on a single virgin browser, in private navigation mode, with a VPN activated (and located in Paris, France, in order only to receive French ads that we would know and could easily categorize).

Creating the Instagram profile for our experiment was not an issue (albeit a little time-consuming): we simply used the email addresses that we had created and signed up to create the profiles. We used gender-neutral aliases that would control for any sort of analysis by Instagram’s algorithms. The name given to our Instagram profile is also gender-neutral, allowing us to control for this variable. 

PROTOCOL

After yet another long brainstorming session, we came up with a strong, reliable protocol to test our hypothesis. Our process is split between two distinct waves of experimentation, as well as two distinct categories for classifying the ads that our profiles are sent.

The first wave
It is not required to enter a gender when creating an instagram account. Thus for the first wave of the experiment, we decide to go with the following six types of profiles: 
Neutral profiles, following “male” content
Neutral profiles, following “female” content 
Neutral profiles, following “non-gendered” content

The profiles act as a control group. We want to verify that the ad algorithm does generate ads based solely on the followed pages. 

The seconde wave
The second wave of experimentation over Instagram’s advertisement strategy uses a broader set of user profiles:

Self-reported Female profiles, following “male” content
Self-reported Female profiles, following “female” content 
Self-reported Female profiles, following “non-gendered” content 
Self-reported Male profiles, following “male” content
Self-reported Male profiles, following “female” content
Self-reported Males profiles, following “non-gendered” content 

The idea is to weigh the importance of self-declared gender in the ad-suggestion algorithm. We seek to determine whether, for instance, if a female who follows typical male content will be suggested the same type of products as a male who follows the same pages.  

THE PAGES FOLLOWED

	We divided the pages in three categories: female-targeting pages, male-targeting pages and non-gendered pages. For the feminine and masculine content, we created a typology of pages: beauty products; audiovisual; luxury; sports and magazines. For the purpose of the experiment, we followed gender stereotypes and hence followed the pages of brands, products and activities that are empirically or culturally associated with a specific gender.  

	It must be noted that our experiment is only as valid as our categories. Indeed, although we tried to establish our categories (“typically male”, ”typically female”, “non-gendered”) as scientifically as possible, our own judgement and personal biases have played a role in defining which ad would be classified as one or the other category. We tried to mitigate our personal biases as much as possible by voting unanimously on the pages to follow.

Feminine pages:
Beauty: L’Oréal, Clarins, Sephora
Audiovisual: Gossip Girls, Gilmore Girls
Luxury: Dior, Chanel 
Sports:  Yoga, Ballet Opéra de Paris 
Press: Elle, Marie claire

	Masculine pages:
Beauty: Gillette, Axe 
Audiovisual: Call of Duty, Fifa
Luxury: Tag Heuer, Rolex, Porsche
Sports: PSG, OM
Press: GQ, Playboy

	Non-gendered pages:
Politics: LREM, EELV
Education: HEC, Institut Montaigne
Audiovisual: Nintendo, the Sims, Game of Thrones
Brands: Nike, Monoprix
Press: Brut, Le Monde

RESULTS 

After following the different pages, we realized no ads were being displayed. As a result we decided to pivot towards the analysis of the “Explore” feature of Instagram that suggests content for the user to like and follow.

We decided to analyse the fifty (50) first contents displayed in the “Explore” feature. For each profile we created, we counted the number of men in the “explore feature”, the number of women, the main type of content displayed and the number of unrelated suggestions.







Graph 1. Content on the Explorer of Male profiles, according to followed pages


Graph 2. Content on the Explorer of Female profiles, according to followed pages












Graph 3. Content on the Explorer of Neutral profiles, according to followed pages


Chart 1. Main content displayed on the Explorer page, according to gender and followed pages



Quantitatively, we found that there is a majority of women in the Explore feature as we found an average of 22 women  for 16 men displayed in the suggestions. This trend is especially noticeable when the pages followed are neutral. Generally speaking, the suggestions were coherent with the preferences we displayed, with an average of 3 unrelated suggested content per profil. This does not come as a surprise since the algorithm suggests content mainly based on preferences.

ANALYSIS

First of all, it seemed clear that the algorithm associates certain categories of content to certain genders. For instance, watches tend to be categorized as “Male” and Video Games as “Non-gendered”. We also identified patterns which could indicate that gender plays a role in the Explorer algorithm, either reinforcing or mitigating certain traits.

Male Profiles

The number of women and the number of men seemed very linked to the profile’s preferences
When feminine pages are followed, 
Masculine content is suggested ; 
Women are displayed in “Masculine settings” (Capture 1)
Capture 1. Male profiles following feminine content



Female Profiles

The number of women and the number of men displayed seemed very linked to the profile’s preferences.
When feminine pages are followed, the content often features children and couples. This could suggest that the Explorer function associates femininity to family values (Capture 2). 
When masculine pages are followed, feminine products are  displayed (Capture 3). This could suggest that Instagram considers women to be indiscriminately interested by feminine products. 



Capture 2. Female profile following feminine pages
 
Capture 3. Female profile following maculine pages

Non-gendered profiles

When the followed pages were non-gendered, we picked up androgynous or genderly ambiguous suggestions (Capture 5). 
Interestingly, we noticed that when non-gendered pages are followed, Explorer tends to display an important amount of people of the gender opposite to the user’s, when the latter is self-declared.






Capture 4. Non-gendered profile following feminine pages



Capture 5. Non-gendered profile following non-gendered content



GENERAL INTERPRETATION

	What we found confirmed that Instagram algorithm’s does take into account additional information for its suggestions and most likely its targeted ads.
	
	This is quite logical as the purpose of suggestions is to go beyond what the user likes and follows to predict what he might like to buy. Yet, it is also interesting to have a glimpse of the stereotypes attached to such mechanisms and reflect on the challenges it can bring. The kids and couple-oriented content displayed in the Female follows feminine pages can, for instance, raise questions about independence and freedom of women.

	Because this experience only hints at small trends, further studies should be carried out to reveal a genuine bias in the algorithm. 

EXPERIMENT LIMITATIONS AND SUGGESTED IMPROVEMENTS 

Data collection issues
The obligation to activate cookies when creating an account may have caused data contamination from one account to another and compromised the seeked impermeability between our own personal internet activity and the experiment.
The browsing data - that keeps track of the engagement and attention generated by a given post - was not controlled for. We hence could have ourselves involuntarily biased our results. 
Protocole issues
It was oftentimes difficult to determine whether suggested content was related to the followed pages or not. For example, if a user follows the PSG page, is a fan’s picture of Neymar’s son a related content ? 
Building our page baskets
We relied on gender stereotypes attached to different interests. Seeing the very large number of followers on the chosen pages, sometimes ranging in tens of millions, it was impossible to verify if a given page really attracted more female users or male users or the opposite. 
The posting propensity of the different pages seemed to have a consequence on their relative weight on the Explorer tab. Brands (Chanel, Rolex, Ferrari) seemed to be more represented on Explorer than TV shows, football clubs or political parties. 
The number of men and women displayed on the Explorer page is a questionable proxy for gender bias. Does liking a woman’s picture reveal masculine or feminine tastes ? 
Interpretation issues
The goal of the Explorer page is not clearly defined by Instagram. If its purpose is to “explore” new and different content, we should not be surprised that some content differs from the usually liked type of pages. 


BIBLIOGRAPHY

Brown, T. W. et al., Exposure to opposing views on social media can increase political polarization, National Academy of Sciences of the USA (2018)

Muhammad Ali et al., Ad Delivery Algorithms: The Hidden Arbiters of Political Messaging, Cornell University Press (2019)

Muhammad Ali, Discrimination through optimization: How Facebook’s ad delivery can lead to skewed outcomes, Cornell University Press (2019)

Jen Gennai, Meghana Bhatt, Take back the Ad: Understanding the impact of female-sexualized ads on male and female viewers (2020)

Jeff Horwitz, Facebook Algorithm Shows Gender Bias in Job Ads, Wall Street Journal (2020)

Rebecca Heilweil, Facebook glitch blocks certain political ads, raising new questions about transparency (2020)

Lambrecht, Anja, Catherine Tucker, An Empirical Study into Apparent Gender-Based Discrimination in the Display of STEM Career Ads, Harvard Kennedy School (2018)

Ava Kofman, Ariana Tobin, Facebook Ads Can Still Discriminate Against Women, Despite a Civil Rights Settlement, ProPublica (2019)

Vox News, Facebook showed this ad to 95% women. Is that a problem?, link, (2020) 

Judith Duportail, Nicolas Kayser-Bril, Edouard Richard, Kira Schacht, The skin bias in Instagram, AlgorithmWatch (2020)









